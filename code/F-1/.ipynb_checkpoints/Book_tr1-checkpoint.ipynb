{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import sys\n",
    "import math\n",
    "\n",
    "if './' not in sys.path:\n",
    "    sys.path.append('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "getfa = {\t\n",
    "\"Movie_tr1\":{\"Dir\":[0,1,2],\"Prod\":[0,1,2],\"SP\":[1],\"SR\":[0,1,2],\"M\":[0,1,2],\"Cin\":[1],\"EdiB\":[0,1,2],\"PC\":[1],\n",
    "    \"Dby\":[0,1,2],\"Rdate\":[0,1,2],\"Rtime\":[1],\"Cty\":[0,1,2],\"Lang\":[0,1,2],\"Budg\":[1],\"BO\":[1]},\n",
    "\"Book_tr1\":{\"Publisher\":[1],\"Schedule\":[1],\"Format\":[0,1,2],\"Genre\":[0,1,2],\"Publication_date\":[1],\n",
    "        \"No_of_issues\":[1],\"Main_character\":[0,1,2],\"Written_by\":[0,1,2]},\n",
    "\"FnD_tr1\":{\"Manufacturer\":[1],\"Country_of_origin\":[0,1,2],\"Variants_Flavour\":[0,1,2],\"Introduced\":[1],\"Related_products\":[0,1,2],\n",
    "    \"Alcohol_by_volume\":[1],\"Website\":[1],\"Color\":[0,1,2],\"Main_ingredients\":[0,1,2],\"Type\":[0,1,2]},\n",
    "\"Organiz_tr1\":{\"Wesbsite\":[1],\"Headquarters\":[1],\"Founded_Formation\":[1],\"Industry\":[0,1,2],\"Key_people\":[0,1,2],\"Products\":[0,1,2]\n",
    "\t,\"Number_of_employees\":[1],\"Traded_as\":[0,1,2],\"Founder_Founders\":[0,1,2],\"Area_served\":[0,1,2],\"Type\":[1],\"Subsidiaries\":[0,1,2]\n",
    "\t,\"Parent\":[1],\"Owner\":[1],\"Predecessor\":[1]},\n",
    "\"Paint_tr1\":{\"Artist\":[1],\"Year\":[1],\"Medium_Type\":[1],\"Dimensions\":[1],\"Location\":[1]},\n",
    "\"Fest_tr1\":{\"Type\":[0,1,2],\"Observed_by\":[0,1,2],\"Frequency\":[1],\"Celebrations\":[0,1,2],\"Significance\":[0,1,2],\"Observances\":[0,1,2],\n",
    "    \"Date\":[1],\"Related_to\":[0,1,2],\"Also_called\":[0,1,2],\"Official_name\":[1],\"Begins\":[1],\"Ends\":[1],\n",
    "    \"2021_date\":[1],\"2020_date\":[1],\"2019_date\":[1],\"2018_date\":[1]},\n",
    "\"SpEv_tr1\":{\"Venue_Location\":[0,1,2],\"Date_Dates\":[1],\"Competitors\":[0,1,2],\"Teams\":[1],\n",
    "\t\"No_of_events\":[1],\"Established_Founded\":[1],\"Official_site\":[1]},\n",
    "\"Univ_tr1\":{\"Website\":[1],\"Type\":[0,1,2],\"Established\":[1],\"Undergraduates\":[1],\"Postgraduates\":[1],\n",
    "    \"Motto_Motto_in_English\":[0,1,2],\"Location\":[1],\"Nickname\":[1],\"Campus\":[1],\"Colors\":[0,1,2],\n",
    "    \"Students\":[1],\"Academic_staff\":[1],\"Administrative_staff\":[1],\"President\":[1],\"Endowment\":[1],\"Mascot\":[1],\n",
    "    \"Provost\":[1],\"Sporting_affiliations\":[0,1,2],\"Academic_affiliations\":[0,1,2],\"Former_names\":[1]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Catg = pd.read_csv(\"/content/drive/My Drive/Auto-TNLI/data/table_categories modified.tsv\",sep=\"\\t\")\n",
    "# Catg = pd.read_csv(\"../../autotnlidatasetandcode/table_categories modified.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ptab = np.array(Catg[Catg.category.isin(['Book'])].table_id)\n",
    "tablesFolder = \"/content/drive/My Drive/Auto-TNLI/data/tables\"\n",
    "# tablesFolder = \"../../autotnlidatasetandcode/tables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseFile(filename, tablesFolder):\n",
    "    soup = BeautifulSoup(open(tablesFolder + '/' + filename, encoding=\"utf8\"), 'html.parser')\n",
    "#     print(soup)\n",
    "    keys =[i.text for i in soup.find('tr').find_all('th')]\n",
    "    vals = []\n",
    "#     soup.replace('br',',')\n",
    "    for i in soup.find('tr').find_all('td'):\n",
    "        result = [val.text.strip().replace(\"\\n\", \"\").replace(\"\\t\", \"\") for val in i.find_all('li')]\n",
    "        if not result:\n",
    "            if(i.find('br')):\n",
    "                for x in i.findAll('br'):\n",
    "                    x.replace_with(',')\n",
    "#                 print(i.text)\n",
    "                result = i.text.split(',')\n",
    "            elif \"â€“\" in i.text:\n",
    "                result = [val.strip().replace(\"\\n\", \"\").replace(\"\\t\", \"\") for val in i.text.split(\"â€“\")]\n",
    "            else:\n",
    "                result = i.text.strip().replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "        vals.append(result)\n",
    "    title = keys[0]\n",
    "    dictionary = dict(zip(keys[1:], vals))\n",
    "    dictionary[\"Title\"] = title\n",
    "    dictionary[\"Tablename\"] = filename.split(\".\")[0]\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Table_Title():\n",
    "    d = {}\n",
    "    tb = []\n",
    "    for n in range(51):\n",
    "        if(int(Ptab[n][1:]) <=2800 ):\n",
    "            dictionary = parseFile(Ptab[n]+\".html\", tablesFolder)\n",
    "            tb.append(dictionary['Tablename'])\n",
    "            if(\"Title\" in dictionary.keys()):\n",
    "#                 print(dictionary['Tablename'],' : ',dictionary['Title'])\n",
    "                d[dictionary['Tablename']] = []\n",
    "                d[dictionary['Tablename']].append(dictionary['Title'])\n",
    "            else:\n",
    "#                 print(dictionary['Tablename'],':',\"!!!\")\n",
    "                d[dictionary['Tablename']] = []\n",
    "                d[dictionary['Tablename']].append(None)\n",
    "    return d,tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N,T = get_Table_Title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "d1 : dict for that table\n",
    "univ : list of a set\n",
    "df : dataframe of Born/Death to get the table name\n",
    "sel: selection bit\n",
    "it : choose table name from the dataframe\n",
    "'''\n",
    "def FakeDICT(tb,dn,univ,di,it,sel=0,subNone = False): # selection bit selects whethet to substitute/delete/add\n",
    "    d1 = di\n",
    "    univ = list(univ)\n",
    "    if(sel==0): # add\n",
    "        if(d1[tb[it]][0]==None):\n",
    "            d1[tb[it]]=[]\n",
    "        ulimit = min(2,len(di[tb[it]])+1) # choose an upper limit of how many to add\n",
    "        n_add = ulimit\n",
    "        if(ulimit>1):\n",
    "            n_add = random.randint(1,ulimit)\n",
    "        add = random.sample(list(set(univ)-set(d1[tb[it]])),n_add)\n",
    "        d1[tb[it]] =  list(set(d1[tb[it]]).union(set(add)))\n",
    "        return d1\n",
    "    elif(sel==1): \n",
    "        if(len(di[tb[it]])>0 and di[tb[it]][0] != None):\n",
    "            if(len(di[tb[it]])>1):\n",
    "                keep = random.sample(d1[tb[it]],1)\n",
    "                ulimit = min(len(list(set(univ)-set(d1[tb[it]]))),len(d1[tb[it]])-1)\n",
    "                substitute = random.sample(list(set(univ)-set(d1[tb[it]])),ulimit)\n",
    "            else:\n",
    "                keep=[]\n",
    "                substitute = random.sample(list(set(univ)-set(d1[tb[it]])),len(d1[tb[it]]))\n",
    "            d1[tb[it]] =  list(set(substitute).union(set(keep)))\n",
    "        elif(len(di[tb[it]])>0):\n",
    "            possible_sub = random.sample(list(set(univ)-set(d1[tb[it]])),1)\n",
    "            for i in range(6): # Probability that none is chose = 1/7\n",
    "                possible_sub.append(random.sample(list(set(univ)-set(d1[tb[it]])),1)[0])\n",
    "            possible_sub.append(None)\n",
    "            sub = random.sample(possible_sub,1)\n",
    "            d1[tb[it]][random.randint(0,len(d1[tb[it]])-1)] = sub[0]\n",
    "        return d1\n",
    "    elif(sel==2): # delete nd : for size = 1\n",
    "        if(len(di[tb[it]])>1 and di[tb[it]][0] != None):\n",
    "            llimit = max(1,len(d1[tb[it]])-1)\n",
    "            keep = random.sample(d1[tb[it]], random.randint(1,llimit) ) \n",
    "            d1[tb[it]] = keep\n",
    "        return d1\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Publisher(T,N,fake=False,sel=0):\n",
    "    u = set([])\n",
    "    d = {}\n",
    "    k = \"Publisher\"\n",
    "    for n in range(51):\n",
    "        if(int(Ptab[n][1:]) <=2800 ):\n",
    "            dictionary = parseFile(Ptab[n]+\".html\", tablesFolder)\n",
    "            if(k in dictionary.keys()):\n",
    "#                 print(dictionary['Tablename'],' : ',dictionary['Starring'])\n",
    "                d[dictionary['Tablename']] = []\n",
    "                if(type(dictionary[k]) == list):\n",
    "                    for i in range(len(dictionary[k])):\n",
    "                        u.add(dictionary[k][i])\n",
    "                        d[dictionary['Tablename']].append(dictionary[k][i])\n",
    "                else:\n",
    "                    u.add(dictionary[k])\n",
    "                    d[dictionary['Tablename']].append(dictionary[k])\n",
    "                    \n",
    "            else:\n",
    "#                 print(dictionary['Tablename'],':',\"!!!\")\n",
    "                d[dictionary['Tablename']] = []\n",
    "                d[dictionary['Tablename']].append(None)\n",
    "        \n",
    "    if(fake):\n",
    "        for it in range(51): # for getting all the fakes in one go\n",
    "            sel = random.sample(getfa[\"Book_tr1\"][k.replace(\" \",\"_\")],1)[0]\n",
    "            if(sel==2 and len(d[T[it]])<2):\n",
    "                sel = 1\n",
    "            d = FakeDICT(T,N,u,d,it,sel)\n",
    "        \n",
    "    return list(u),d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Schedule(T,N,fake=False,sel=0):\n",
    "    u = set([])\n",
    "    d = {}\n",
    "    k = \"Schedule\"\n",
    "    for n in range(51):\n",
    "        if(int(Ptab[n][1:]) <=2800 ):\n",
    "            dictionary = parseFile(Ptab[n]+\".html\", tablesFolder)\n",
    "            if(k in dictionary.keys()):\n",
    "#                 print(dictionary['Tablename'],' : ',dictionary['Starring'])\n",
    "                d[dictionary['Tablename']] = []\n",
    "                if(type(dictionary[k]) == list):\n",
    "                    for i in range(len(dictionary[k])):\n",
    "                        u.add(dictionary[k][i])\n",
    "                        d[dictionary['Tablename']].append(dictionary[k][i])\n",
    "                else:\n",
    "                    u.add(dictionary[k])\n",
    "                    d[dictionary['Tablename']].append(dictionary[k])\n",
    "                    \n",
    "            else:\n",
    "#                 print(dictionary['Tablename'],':',\"!!!\")\n",
    "                d[dictionary['Tablename']] = []\n",
    "                d[dictionary['Tablename']].append(None)\n",
    "        \n",
    "    if(fake):\n",
    "        for it in range(51): # for getting all the fakes in one go\n",
    "            sel = random.sample(getfa[\"Book_tr1\"][k.replace(\" \",\"_\")],1)[0]\n",
    "            if(sel==2 and len(d[T[it]])<2):\n",
    "                sel = 1\n",
    "            d = FakeDICT(T,N,u,d,it,sel)\n",
    "        \n",
    "    return list(u),d        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U,D = getSch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Format(T,N,fake=False,sel=0):\n",
    "    u = set([])\n",
    "    d = {}\n",
    "    k = \"Format\"\n",
    "    for n in range(51):\n",
    "        if(int(Ptab[n][1:]) <=2800 ):\n",
    "            dictionary = parseFile(Ptab[n]+\".html\", tablesFolder)\n",
    "            if(k in dictionary.keys()):\n",
    "#                 print(dictionary['Tablename'],' : ',dictionary['Starring'])\n",
    "                d[dictionary['Tablename']] = []\n",
    "                if(type(dictionary[k]) == list):\n",
    "                    for i in range(len(dictionary[k])):\n",
    "                        u.add(dictionary[k][i])\n",
    "                        d[dictionary['Tablename']].append(dictionary[k][i])\n",
    "                else:\n",
    "                    u.add(dictionary[k])\n",
    "                    d[dictionary['Tablename']].append(dictionary[k])\n",
    "                    \n",
    "            else:\n",
    "#                 print(dictionary['Tablename'],':',\"!!!\")\n",
    "                d[dictionary['Tablename']] = []\n",
    "                d[dictionary['Tablename']].append(None)\n",
    "        \n",
    "    if(fake):\n",
    "        for it in range(51): # for getting all the fakes in one go\n",
    "            sel = random.sample(getfa[\"Book_tr1\"][k.replace(\" \",\"_\")],1)[0]\n",
    "            if(sel==2 and len(d[T[it]])<2):\n",
    "                sel = 1\n",
    "            d = FakeDICT(T,N,u,d,it,sel)\n",
    "        \n",
    "    return list(u),d        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U,D = getFmt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Genre(T,N,fake=False,sel=0):\n",
    "    u = set([])\n",
    "    d = {}\n",
    "    k = \"Genre\"\n",
    "    for n in range(51):\n",
    "        if(int(Ptab[n][1:]) <=2800 ):\n",
    "            dictionary = parseFile(Ptab[n]+\".html\", tablesFolder)\n",
    "            if(k in dictionary.keys()):\n",
    "#                 print(dictionary['Tablename'],' : ',dictionary['Starring'])\n",
    "                d[dictionary['Tablename']] = []\n",
    "                if(type(dictionary[k]) == list):\n",
    "                    for i in range(len(dictionary[k])):\n",
    "                        u.add(dictionary[k][i].strip().lower())\n",
    "                        d[dictionary['Tablename']].append(dictionary[k][i].strip().lower())\n",
    "                elif(len(dictionary[k].split(','))>1):\n",
    "                    for i in range(len(dictionary[k].split(','))):\n",
    "                        u.add(dictionary[k].split(',')[i].strip().lower())\n",
    "                        d[dictionary['Tablename']].append(dictionary[k].split(',')[i].strip().lower())\n",
    "                else:\n",
    "                    u.add(dictionary[k].strip().lower())\n",
    "                    d[dictionary['Tablename']].append(dictionary[k].strip().lower())\n",
    "                    \n",
    "            else:\n",
    "#                 print(dictionary['Tablename'],':',\"!!!\")\n",
    "                d[dictionary['Tablename']] = []\n",
    "                d[dictionary['Tablename']].append(None)\n",
    "        \n",
    "    if(fake):\n",
    "        for it in range(51): # for getting all the fakes in one go\n",
    "            sel = random.sample(getfa[\"Book_tr1\"][k.replace(\" \",\"_\")],1)[0]\n",
    "            if(sel==2 and len(d[T[it]])<2):\n",
    "                sel = 1\n",
    "            d = FakeDICT(T,N,u,d,it,sel)\n",
    "        \n",
    "    return list(u),d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getGen()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Publication_date(T,N,fake=False,sel=0):\n",
    "    u = set([])\n",
    "    d = {}\n",
    "    k = \"Publication date\"\n",
    "    for n in range(51):\n",
    "        if(int(Ptab[n][1:]) <=2800 ):\n",
    "            dictionary = parseFile(Ptab[n]+\".html\", tablesFolder)\n",
    "            if(k in dictionary.keys()):\n",
    "#                 print(dictionary['Tablename'],' : ',dictionary['Starring'])\n",
    "                d[dictionary['Tablename']] = []\n",
    "                if(type(dictionary[k]) == list):\n",
    "                    for i in range(len(dictionary[k])):\n",
    "                        u.add(dictionary[k][i].replace('\\xa0',' '))\n",
    "                        d[dictionary['Tablename']].append(dictionary[k][i].replace('\\xa0',' '))\n",
    "                else:\n",
    "                    u.add(dictionary[k].replace('\\xa0',' '))\n",
    "                    d[dictionary['Tablename']].append(dictionary[k].replace('\\xa0',' '))\n",
    "                    \n",
    "            else:\n",
    "#                 print(dictionary['Tablename'],':',\"!!!\")\n",
    "                d[dictionary['Tablename']] = []\n",
    "                d[dictionary['Tablename']].append(None)\n",
    "        \n",
    "    if(fake):\n",
    "        for it in range(51): # for getting all the fakes in one go\n",
    "            sel = random.sample(getfa[\"Book_tr1\"][k.replace(\" \",\"_\")],1)[0]\n",
    "            if(sel==2 and len(d[T[it]])<2):\n",
    "                sel = 1\n",
    "            d = FakeDICT(T,N,u,d,it,sel)\n",
    "        \n",
    "    return list(u),d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U,D = getPubDate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_No_of_issues(T,N,fake=False,sel=0):\n",
    "    u = set([])\n",
    "    d = {}\n",
    "    k = \"No. of issues\"\n",
    "    for n in range(51):\n",
    "        if(int(Ptab[n][1:]) <=2800 ):\n",
    "            dictionary = parseFile(Ptab[n]+\".html\", tablesFolder)\n",
    "            if(k in dictionary.keys()):\n",
    "#                 print(dictionary['Tablename'],' : ',dictionary['Starring'])\n",
    "                d[dictionary['Tablename']] = []\n",
    "#                 d[dictionary['Tablename']].append(dictionary[k])\n",
    "                if(type(dictionary[k]) == list):\n",
    "                    r = re.findall(\"[0-9]+\",\",\".join(dictionary[k])) \n",
    "                    s = 0\n",
    "                    for i in range(len(r)):\n",
    "                        s += int(r[i])     \n",
    "                    u.add(s)\n",
    "                    d[dictionary['Tablename']].append(s)\n",
    "                else:\n",
    "                    r = re.findall(\"[0-9]+\",dictionary[k])\n",
    "                    s = 0\n",
    "                    for i in range(len(r)):\n",
    "                        s += int(r[i])\n",
    "                    u.add(s)\n",
    "                    d[dictionary['Tablename']].append(s)\n",
    "                    \n",
    "            else:\n",
    "#                 print(dictionary['Tablename'],':',\"!!!\")\n",
    "                d[dictionary['Tablename']] = []\n",
    "                d[dictionary['Tablename']].append(None)\n",
    "        \n",
    "    if(fake):\n",
    "        for it in range(51): # for getting all the fakes in one go\n",
    "            sel = random.sample(getfa[\"Book_tr1\"][\"No_of_issues\"],1)[0]\n",
    "            if(sel==2 and len(d[T[it]])<2):\n",
    "                sel = 1\n",
    "            d = FakeDICT(T,N,u,d,it,sel)\n",
    "        \n",
    "    return list(u),d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getNI()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Main_character(T,N,fake=False,sel=0):\n",
    "    u = set([])\n",
    "    d = {}\n",
    "    k = \"Main character(s)\"\n",
    "    for n in range(51):\n",
    "        if(int(Ptab[n][1:]) <=2800 ):\n",
    "            dictionary = parseFile(Ptab[n]+\".html\", tablesFolder)\n",
    "            if(k in dictionary.keys()):\n",
    "#                 print(dictionary['Tablename'],' : ',dictionary['Starring'])\n",
    "                d[dictionary['Tablename']] = []\n",
    "                if(type(dictionary[k]) == list):\n",
    "                    for i in range(len(dictionary[k])):\n",
    "                        u.add(dictionary[k][i])\n",
    "                        d[dictionary['Tablename']].append(dictionary[k][i])\n",
    "                else:\n",
    "                    u.add(dictionary[k])\n",
    "                    d[dictionary['Tablename']].append(dictionary[k])\n",
    "                    \n",
    "            else:\n",
    "#                 print(dictionary['Tablename'],':',\"!!!\")\n",
    "                d[dictionary['Tablename']] = []\n",
    "                d[dictionary['Tablename']].append(None)\n",
    "    \n",
    "    if(fake):\n",
    "        for it in range(51): # for getting all the fakes in one go\n",
    "            sel = random.sample(getfa[\"Book_tr1\"][\"Main_character\"],1)[0]\n",
    "            if(sel==2 and len(d[T[it]])<2):\n",
    "                sel = 1\n",
    "            d = FakeDICT(T,N,u,d,it,sel)\n",
    "        \n",
    "    return list(u),d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U,D = getMChar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Written_by(T,N,fake=False,sel=0):\n",
    "    u = set([])\n",
    "    d = {}\n",
    "    k = \"Written by\"\n",
    "    for n in range(51):\n",
    "        if(int(Ptab[n][1:]) <=2800 ):\n",
    "            dictionary = parseFile(Ptab[n]+\".html\", tablesFolder)\n",
    "            if(k in dictionary.keys()):\n",
    "#                 print(dictionary['Tablename'],' : ',dictionary['Starring'])\n",
    "                d[dictionary['Tablename']] = []\n",
    "                if(type(dictionary[k]) == list):\n",
    "                    for i in range(len(dictionary[k])):\n",
    "                        u.add(dictionary[k][i])\n",
    "                        d[dictionary['Tablename']].append(dictionary[k][i])\n",
    "                else:\n",
    "                    u.add(dictionary[k])\n",
    "                    d[dictionary['Tablename']].append(dictionary[k])\n",
    "                    \n",
    "            else:\n",
    "#                 print(dictionary['Tablename'],':',\"!!!\")\n",
    "                d[dictionary['Tablename']] = []\n",
    "                d[dictionary['Tablename']].append(None)\n",
    "    if(fake):\n",
    "        for it in range(51): # for getting all the fakes in one go\n",
    "            sel = random.sample(getfa[\"Book_tr1\"][k.replace(\" \",\"_\")],1)[0]\n",
    "            if(sel==2 and len(d[T[it]])<2):\n",
    "                sel = 1\n",
    "            d = FakeDICT(T,N,u,d,it,sel)\n",
    "        \n",
    "    return list(u),d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract all data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Data(fake=False):\n",
    "    \n",
    "    Extracted_data = {}\n",
    "    Keys=[\"Publisher\",\"Schedule\",\"Format\",\"Genre\",\"Publication_date\"\n",
    "                           ,\"No_of_issues\",\"Main_character\",\"Written_by\"]\n",
    "    for k in Keys:\n",
    "        Extracted_data[k]=[]\n",
    "        for l in eval(\"get_\"+k)(T,N,fake):\n",
    "            Extracted_data[k].append(l)\n",
    "            \n",
    "    return Extracted_data\n",
    "# F is the Extracted_data[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_Data()[\"Publisher\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentences :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PublisherSent(tb,dn,F,it,tval = True,prem = False):\n",
    "    di = F[1]\n",
    "    univ = F[0]\n",
    "    if(prem):\n",
    "        if(di[tb[it]][0] != None):\n",
    "            All = \",\".join(di[tb[it]])\n",
    "            ps1 = [ \"The name of the book is \"+dn[tb[it]][0]+\"and it was published by \"+All\n",
    "                   , All+\" published ,The book named \"+dn[tb[it]][0]\n",
    "                   , \"The book named\"+dn[tb[it]][0]+\" was published by \"+All ]\n",
    "        else:\n",
    "            ps1=[None]\n",
    "        return ps1\n",
    "    \n",
    "    else:\n",
    "        if(di[tb[it]][0]!= None):\n",
    "            if(tval):\n",
    "                All = ','.join(di[tb[it]])\n",
    "                ts1 = [dn[tb[it]][0] + \" was published by \" + All\n",
    "                    ,All + \" is the publisher of the \" + dn[tb[it]][0]]\n",
    "            else:\n",
    "                NT = random.sample(list(set(univ)-set(di[tb[it]])),random.randint(1,2))\n",
    "                All = ','.join(NT)\n",
    "                ts1 = [ dn[tb[it]][0] + \" was published by \" + All\n",
    "                    ,All + \" is the publisher of the \" + dn[tb[it]][0] ]\n",
    "        else:\n",
    "            ts1 = [None]\n",
    "    \n",
    "        return ts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PublisherSent(T,N,get_Publisher(T,N),51,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ScheduleSent(tb,dn,F,it,tval = True,prem = False):\n",
    "    di = F[1]\n",
    "    univ = F[0]\n",
    "    if(prem):\n",
    "        if(di[tb[it]][0] != None):\n",
    "            All = ','.join(di[tb[it]])\n",
    "            ps1 = [ \"It used to be published \"+All \n",
    "                   , All+\" an issue of this book was published\"\n",
    "                   , \"An issue used to be published \"+All ]\n",
    "        else:\n",
    "            ps1=[None]\n",
    "            \n",
    "        return ps1\n",
    "    \n",
    "    else:\n",
    "        if(di[tb[it]][0] != None):\n",
    "            if(tval):\n",
    "                All = ','.join(di[tb[it]])\n",
    "                ts1 = [ dn[tb[it]][0] + \" was published \" + All\n",
    "                    ,dn[tb[it]][0]+ \" is a \" + All + \" book\"]\n",
    "            else:\n",
    "                NT = random.sample(list(set(univ)-set(di[tb[it]])),random.randint(1,2))\n",
    "                All = ','.join(NT)\n",
    "                ts1 = [dn[tb[it]][0] + \" was published \" + All\n",
    "                    ,dn[tb[it]][0]+ \" is a \" + All + \" book\"]\n",
    "        else:\n",
    "            ts1=[None]\n",
    "    return ts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SchSent(T,N,getSch()[1],getSch()[0],4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FormatSent(tb,dn,F,it,tval = True,prem = False):\n",
    "    di = F[1]\n",
    "    univ = F[0]\n",
    "    if(prem):\n",
    "        if(di[tb[it]][0] != None):\n",
    "            All = ','.join(di[tb[it]])\n",
    "            ps1 = [ \"It is a \"+All , dn[tb[it]][0]+\" was a \"+All ]\n",
    "        else:\n",
    "            ps1 = [None]\n",
    "            \n",
    "        return ps1\n",
    "    \n",
    "    else:\n",
    "        if(di[tb[it]][0] != None):\n",
    "            if(tval):\n",
    "                All = ','.join(di[tb[it]])\n",
    "                ts1 = [dn[tb[it]][0] + \" is a \" + All]\n",
    "            else:\n",
    "                NT = random.sample(list(set(univ)-set(di[tb[it]])),1)\n",
    "                All = ','.join(NT)\n",
    "                ts1 = [dn[tb[it]][0] + \" is a \" + All]\n",
    "        else:\n",
    "            ts1 = [None]\n",
    "        return ts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FmtSent(T,N,getFmt()[1],getFmt()[0],4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenreSent(tb,dn,F,it,tval = True,prem = False):\n",
    "    di = F[1]\n",
    "    univ = F[0]\n",
    "    if(prem):\n",
    "        if(di[tb[it]][0] != None):\n",
    "            All = ','.join(di[tb[it]])\n",
    "            ps1 = [\"It falls in \"+All+\" category\"\n",
    "                   ,\"This book is of \"+All+\" genre\"\n",
    "                   ,dn[tb[it]][0]+\" is of \"+All+\" genre\" ]\n",
    "        else:\n",
    "            ps1=[None]\n",
    "            \n",
    "        return ps1\n",
    "    else:\n",
    "        if(di[tb[it]][0] != None):\n",
    "            if(tval):\n",
    "                All = ','.join(di[tb[it]])\n",
    "                ts1 = [dn[tb[it]][0] + \" falls in the genres of \" + All\n",
    "                    ,dn[tb[it]][0] + \" is a \" + random.sample(di[tb[it]],1)[0] +\" book\"\n",
    "                    ,dn[tb[it]][0] + \" falls into \"+ str(len(di[tb[it]])) + \" category\"]\n",
    "            else:\n",
    "                NT = random.sample(list(set(univ)-set(di[tb[it]])),random.randint(1,3))\n",
    "                All = ','.join(NT)\n",
    "                ts1 = [dn[tb[it]][0] + \" falls in the genres of \" + All\n",
    "                    ,dn[tb[it]][0] + \" is a \" + random.sample(NT,1)[0] +\" book\"\n",
    "                    ,dn[tb[it]][0] + \" falls into \"+ str(len(NT)) + \" category\"]\n",
    "        else:\n",
    "            ts1=[None]\n",
    "\n",
    "        return ts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GenSent(T,N,getGen()[1],getGen()[0],10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Publication_dateSent(tb,dn,F,it,tval = True,prem = False):\n",
    "    di = F[1]\n",
    "    univ = F[0]\n",
    "    if(prem):\n",
    "        if(di[tb[it]][0] != None):\n",
    "            ps1 = [\"This book was published in \"+ \",\".join(di[tb[it]])]\n",
    "        else:\n",
    "            ps1=[None]\n",
    "            \n",
    "        return ps1\n",
    "    \n",
    "    else:\n",
    "        if(di[tb[it]][0] != None):\n",
    "            if(tval):\n",
    "                ts1 = [dn[tb[it]][0] + \" was published from \" + random.sample(di[tb[it]],1)[0]\n",
    "                    ,dn[tb[it]][0] + \" was published in year \" + re.findall(\"[0-9][0-9]+\",random.sample(di[tb[it]],1)[0])[0]\n",
    "                    ,dn[tb[it]][0]+\" was published before \"+str(int(re.findall(\"[0-9][0-9]+\",random.sample(di[tb[it]],1)[0])[-1])+3)\n",
    "                    ,dn[tb[it]][0]+\" was published after \"+str(int(re.findall(\"[0-9][0-9]+\",random.sample(di[tb[it]],1)[0])[0])-2)]\n",
    "            else:\n",
    "                NT = random.sample(list(set(univ)-set(di[tb[it]])),1)\n",
    "                ts1 = [dn[tb[it]][0] + \" was published from \" + NT[0]\n",
    "                    ,dn[tb[it]][0] + \" was published in year \" + re.findall(\"[0-9][0-9]+\",NT[0])[0]\n",
    "                    ,dn[tb[it]][0]+\" was published after \"+str(int(re.findall(\"[0-9][0-9]+\",random.sample(di[tb[it]],1)[0])[-1])+3)\n",
    "                    ,dn[tb[it]][0]+\" was published before \"+str(int(re.findall(\"[0-9][0-9]+\",random.sample(di[tb[it]],1)[0])[0])-2)]\n",
    "        else:\n",
    "            ts1 = [None]\n",
    "        return ts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PubDateSent(T,N,getPubDate()[1],getPubDate()[0],5,False,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def No_of_issuesSent(tb,dn,F,it,tval=True,prem=False):\n",
    "    di = F[1]\n",
    "    univ = F[0]\n",
    "#     syn = [\" went to \",\" worked at \",\" employed at \",]\n",
    "    if(prem):\n",
    "        if(di[tb[it]][0] != None):\n",
    "#         All = ','.join(di[tb[it]])\n",
    "            ps1 = [ \"The no. of issues of the book is \"+str(di[tb[it]][0])\n",
    "                  , \"The book has \"+str(di[tb[it]][0])+\" issues\"]\n",
    "        else:\n",
    "            ps1=[None]\n",
    "            \n",
    "        return ps1\n",
    "    else:\n",
    "        ts = []\n",
    "        if(di[tb[it]][0] != None):\n",
    "#             length = len(di[tb[it]])\n",
    "            if(tval):\n",
    "#                 All = ','.join(di[tb[it]])\n",
    "                ts.append(dn[tb[it]][0]+\" had \"+str(di[tb[it]][0])+\" issues\" )\n",
    "                ts.append(dn[tb[it]][0]+\" had more than \"+str(random.randint(0,di[tb[it]][0]-1))+\" issues\")\n",
    "                ts.append(dn[tb[it]][0]+\" had less than \"+str(random.randint(di[tb[it]][0]+2,di[tb[it]][0]+15))+\" issues\")\n",
    "            else:\n",
    "                NT = random.sample(list(set(univ)-set(di[tb[it]])),1)\n",
    "#                 All = ','.join(NT)\n",
    "                ts.append(dn[tb[it]][0]+\" had \"+str(random.randint(di[tb[it]][0]+2,di[tb[it]][0]+15))+\" issues\" )\n",
    "                ts.append(dn[tb[it]][0]+\" had less than \"+str(random.randint(0,di[tb[it]][0]-1))+\" issues\")\n",
    "                ts.append(dn[tb[it]][0]+\" had more than \"+str(random.randint(di[tb[it]][0]+2,di[tb[it]][0]+15))+\" issues\")\n",
    "        else:\n",
    "            ts.append(None)\n",
    "        \n",
    "        return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NISent(T,N,getNI()[1],getNI()[0],1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Main_characterSent(tb,dn,F,it,tval = True,prem = False):\n",
    "    di = F[1]\n",
    "    univ = F[0]\n",
    "    if(prem):\n",
    "        if(di[tb[it]][0] != None):\n",
    "            All = \",\".join(di[tb[it]])\n",
    "            ps1 =['The main characters of this book are '+All , All+\"are the main characters of the book\"] \n",
    "        else:\n",
    "            ps1=[None]\n",
    "        return ps1\n",
    "    \n",
    "    else:\n",
    "        if(di[tb[it]][0] != None):\n",
    "            if(tval):\n",
    "                ts1 = [random.sample(di[tb[it]],1)[0] + \" was a main character in \" + dn[tb[it]][0]\n",
    "                ,random.sample(di[tb[it]],1)[0] + \" was a character in the book\"\n",
    "                ,\"There are \"+str(len(di[tb[it]])) + \" characters in the book\"\n",
    "                ,\"The book has more than \"+str(len(di[tb[it]])-random.randint(1,len(di[tb[it]])))+\" characters\"\n",
    "                ,\"The book has less than \"+str(len(di[tb[it]])+random.randint(1,4))+\" characters\"]\n",
    "            else:\n",
    "                NT = random.sample(list(set(univ)-set(di[tb[it]])),random.randint(1,3))\n",
    "                ts1 = [random.sample(NT,1)[0] + \" was a main character in \" + dn[tb[it]][0]\n",
    "                ,random.sample(NT,1)[0] + \" was a character in the book\"\n",
    "                ,\"There are \"+str(len(NT)) + \" characters in the book\"\n",
    "                ,\"The book has less than \"+str(len(di[tb[it]])-random.randint(1,len(di[tb[it]])))+\" characters\"\n",
    "                ,\"The book has more than \"+str(len(di[tb[it]])+random.randint(1,4))+\" characters\"]\n",
    "        else:\n",
    "            ts1 = [None]\n",
    "        return ts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCharSent(T,N,getMChar()[1],getMChar()[0],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Written_bySent(tb,dn,F,it,tval = True,prem = False):\n",
    "    di = F[1]\n",
    "    univ = F[0]\n",
    "    if(prem):\n",
    "        if(di[tb[it]][0] != None):\n",
    "            All = \",\".join(di[tb[it]])\n",
    "            ps1 =[\"The book was written by \"+All,All+\"wrote the book \"+dn[tb[it]][0]] \n",
    "        else:\n",
    "            ps1=[None]\n",
    "        return ps1\n",
    "    \n",
    "    else:\n",
    "        if(di[tb[it]][0] != None):\n",
    "            if(tval):\n",
    "                All = ','.join(di[tb[it]])\n",
    "                ts1 = [\"The book was authored by \"+All\n",
    "                ,All+\" authored the book\"\n",
    "                ,\"The book is by \"+random.sample(di[tb[it]],1)[0]\n",
    "                ,random.sample(di[tb[it]],1)[0]+\" is the author of \"+dn[tb[it]][0] ]\n",
    "            else:\n",
    "                NT = random.sample(list(set(univ)-set(di[tb[it]])),random.randint(1,2))\n",
    "                All = ','.join(NT)\n",
    "                ts1 = [\"The book was authored by \"+All\n",
    "                ,All+\" authored the book\"\n",
    "                ,\"The book is by \"+random.sample(NT,1)[0]\n",
    "                ,random.sample(NT,1)[0]+\" is the author of \"+dn[tb[it]][0] ]\n",
    "        else:\n",
    "            ts1=[None]\n",
    "        \n",
    "        return ts1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WbySent(T,N,getWby()[1],getWby()[0],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_row1(tb,dn,F,it,tval=True):\n",
    "    Ug,G = F[\"Genre\"]\n",
    "    Up,P = F[\"Publisher\"]\n",
    "    Uni,Ni = F[\"No_of_issues\"]\n",
    "    \n",
    "#     count_gp = {} # publishers per genre\n",
    "#     count_gni = {} # issues per genre\n",
    "    \n",
    "#     for i in Ni.keys():\n",
    "#         if(Ni[i][0] != None and G[i][0] != None):\n",
    "#             for j in G[i]:\n",
    "#                 if j in count_gni.keys():\n",
    "#                     count_gni[j] += Ni[i][0]\n",
    "#                 else:\n",
    "#                     count_gni[j] = Ni[i][0]\n",
    "                    \n",
    "#     for i in P.keys():\n",
    "#         if(G[i][0] != None and P[i][0] != None):\n",
    "#             for j in G[i]:\n",
    "#                 if j in count_gp.keys():\n",
    "#                     count_gp[j] += 1\n",
    "#                 else:\n",
    "#                     count_gp[j] = 1\n",
    "                    \n",
    "    ts = {}\n",
    "    \n",
    "    if(tval):\n",
    "#         ts1 = []\n",
    "#         for i in count_gni.keys():\n",
    "#             ts1.append(str(count_gni[i])+\" publishers published in \"+i+\" genre\")\n",
    "#         ts2 = []\n",
    "#         for i in count_gp.keys():\n",
    "#             ts2.append(str(count_gp[i])+\" number of issues in \"+i+\" genre\")\n",
    "#         ts =[]\n",
    "#         [g1,g2] = random.sample(count_gp.keys(),2)\n",
    "#         ts.append( \"There are \"+(\"more\" if (count_gp[g1]>count_gp[g2]) else \"less\" )+\" publishers in \"+g1+\"than in \"+g2+\" genre\" )\n",
    "#         [g1,g2] = random.sample(count_gni.keys(),2)\n",
    "#         ts.append( \"There are \"+(\"more\" if (count_gni[g1]>count_gni[g2]) else \"less\" )+\" number of issues in \"+g1+\"than in \"+g2+\" genre\" )\n",
    "        if(P[tb[it]][0]!= None and G[tb[it]][0] != None):\n",
    "            ts[\"Publisher,Genre\"] = []\n",
    "            Al1 = \",\".join(P[tb[it]])\n",
    "            Al2 = \",\".join(random.sample(G[tb[it]],random.randint(1,len(G[tb[it]])) ) )\n",
    "            ts[\"Publisher,Genre\"].append(Al1+\" publishes in \"+Al2+\" genres\")\n",
    "        if(Ni[tb[it]][0]!= None and G[tb[it]][0] != None):\n",
    "            ts[\"No_of_issues,Genre\"] = []\n",
    "#             Al1 = \",\".join(P[tb[it]])\n",
    "            Al2 = \",\".join(random.sample(G[tb[it]],random.randint(1,len(G[tb[it]])) ) )\n",
    "            ts[\"No_of_issues,Genre\"].append(str(Ni[tb[it]][0])+\" number of issues in \"+Al2+\"genres\")\n",
    "            ts[\"No_of_issues,Genre\"].append(\"There are \"+(\"more\" if (Ni[tb[it]][0]>len(G[tb[it]])) else \"less\") +\" number of issues than genres\")\n",
    "            \n",
    "    else:\n",
    "#         ts1 = []\n",
    "#         for i in count_gni.keys():\n",
    "#             ts1.append(str(random.randint(count_gni[i]+1,count_gni[i]+10))+\" publishers published in \"+i+\" genre\")\n",
    "#         ts2 = []\n",
    "#         for i in count_gp.keys():\n",
    "#             ts2.append(str(random.randint(count_gp[i]+1,count_gp[i]+10))+\" number of issues in \"+i+\" genre\")\n",
    "#         ts = []\n",
    "#         [g1,g2] = random.sample(count_gp.keys(),2)\n",
    "#         ts.append( \"There are \"+(\"more\" if (count_gp[g1]<count_gp[g2]) else \"less\")+\" publishers in \"+g1+\"than in \"+g2+\" genre\" )\n",
    "#         [g1,g2] = random.sample(count_gni.keys(),2)\n",
    "#         ts.append( \"There are \"+(\"more\" if (count_gni[g1]<count_gni[g2]) else \"less\")+\" number of issues in \"+g1+\"than in \"+g2+\" genre\" )        \n",
    "        if(P[tb[it]][0]!= None and G[tb[it]][0] != None):\n",
    "            ts[\"Publisher,Genre\"] = []\n",
    "            Al1 = \",\".join(P[tb[it]])\n",
    "            NT = random.sample(list(set(Ug)-set(G[tb[it]])),random.randint(3,5))\n",
    "            Al2 = \",\".join(random.sample(NT,random.randint(1,len(NT)) ) )\n",
    "            ts[\"Publisher,Genre\"].append(Al1+\" publishes in \"+Al2+\" genres\")\n",
    "        if(Ni[tb[it]][0]!= None and G[tb[it]][0] != None):\n",
    "            ts[\"No_of_issues,Genre\"] = []\n",
    "#             Al1 = \",\".join(P[tb[it]])\n",
    "            Al2 = \",\".join(random.sample(G[tb[it]],random.randint(1,len(G[tb[it]])) ) )\n",
    "            ts[\"No_of_issues,Genre\"].append(str(random.randint(Ni[tb[it]][0]+1,Ni[tb[it]][0]+10))+\" number of issues in \"+Al2+\"genres\")\n",
    "            ts[\"No_of_issues,Genre\"].append(\"There are \"+(\"more\" if (Ni[tb[it]][0]<len(G[tb[it]])) else \"less\") +\" number of issues than genres\")\n",
    "        \n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi_row1(T,N,10)[3]\n",
    "# getGen()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_row2(tb,dn,F1,it,tval=True):\n",
    "    Uw,W = F1[\"Written_by\"]\n",
    "    Us,S = F1[\"Schedule\"]\n",
    "    Up,P = F1[\"Publisher\"]\n",
    "    Uf,F = F1[\"Format\"]\n",
    "    \n",
    "    ts = {}\n",
    "    if(tval):\n",
    "        if(P[tb[it]][0] != None and S[tb[it]][0] != None):\n",
    "            ts[\"Publisher,Schedule\"] = []\n",
    "            ts[\"Publisher,Schedule\"].append( \",\".join(P[tb[it]])+\" publishes \"+\",\".join(S[tb[it]]) )\n",
    "        if(P[tb[it]][0] != None and F[tb[it]][0] != None):\n",
    "            ts[\"Publisher,Format\"] = []\n",
    "            ts[\"Publisher,Format\"].append( \",\".join(P[tb[it]])+\" publishes in \"+F[tb[it]][0]+\" format\" )\n",
    "        if(W[tb[it]][0] != None and F[tb[it]][0] != None):\n",
    "            ts[\"Written_by,Format\"] = []\n",
    "            ts[\"Written_by,Format\"].append( \",\".join(W[tb[it]])+\" writes in \"+F[tb[it]][0]+ \" format\" )\n",
    "    else:\n",
    "        if(P[tb[it]][0] != None and S[tb[it]][0] != None):\n",
    "            ts[\"Publisher,Schedule\"] = []\n",
    "            NP = random.sample(list(set(Up)-set(P[tb[it]])),random.randint(1,2))\n",
    "            NS = random.sample(list(set(Us)-set(S[tb[it]])),1)\n",
    "            ts[\"Publisher,Schedule\"].append( \",\".join(P[tb[it]])+\" publishes \"+\",\".join(NS) )\n",
    "        if(P[tb[it]][0] != None and F[tb[it]][0] != None):\n",
    "            ts[\"Publisher,Format\"] = []\n",
    "            NP = random.sample(list(set(Up)-set(P[tb[it]])),random.randint(1,2))\n",
    "            NF = random.sample(list(set(Uf)-set(F[tb[it]])),1)\n",
    "            ts[\"Publisher,Format\"].append( \",\".join(NP)+\" publishes in \"+F[tb[it]][0]+\" format\" )\n",
    "        if(W[tb[it]][0] != None and F[tb[it]][0] != None):\n",
    "            ts[\"Written_by,Format\"] = []\n",
    "            NW = random.sample(list(set(Uw)-set(W[tb[it]])),random.randint(1,2))\n",
    "            NF = random.sample(list(set(Uf)-set(F[tb[it]])),1)\n",
    "            ts[\"Written_by,Format\"].append( \",\".join(NW)+\" writes in \"+NF[0]+ \" format\" )\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi_row2(T,N,8,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_row3(tb,dn,F,it,tval=True):\n",
    "    Uw,W = F[\"Written_by\"]\n",
    "    Um,M = F[\"Main_character\"]\n",
    "    Up,P = F[\"Publisher\"]\n",
    "    Us,S = F[\"Schedule\"]\n",
    "    \n",
    "    ts = {}\n",
    "    if(tval):\n",
    "        if(M[tb[it]][0] != None and W[tb[it]][0] != None):\n",
    "            ts[\"Main_character,Written_by\"] = []\n",
    "            Al1 = \",\".join(M[tb[it]])\n",
    "            Al2 = \",\".join(W[tb[it]])\n",
    "            ts[\"Main_character,Written_by\"].append(\"Book about \"+Al1+\" was written by \"+Al2)\n",
    "        if(M[tb[it]][0] != None and P[tb[it]][0] != None):\n",
    "            ts[\"Main_character,Publisher\"] = []\n",
    "            Al1 = \",\".join(M[tb[it]])\n",
    "            Al2 = \",\".join(P[tb[it]])\n",
    "            ts[\"Main_character,Publisher\"].append(\"Book about \"+Al1+\" is published by \"+Al2)\n",
    "        if(M[tb[it]][0] != None and S[tb[it]][0] != None):\n",
    "            ts[\"Main_character,Schedule\"] = []\n",
    "            Al1 = \",\".join(M[tb[it]])\n",
    "            Al2 = \",\".join(S[tb[it]])\n",
    "            ts[\"Main_character,Schedule\"].append(\"Book about \"+Al1+\" is published \"+Al2)\n",
    "        \n",
    "    else:\n",
    "        if(M[tb[it]][0] != None and W[tb[it]][0] != None):\n",
    "            ts[\"Main_character,Written_by\"] = []\n",
    "            NM = random.sample(list(set(Um)-set(M[tb[it]])),random.randint(1,3))\n",
    "            NW = random.sample(list(set(Uw)-set(W[tb[it]])),random.randint(1,2))\n",
    "            Al1 = \",\".join(NM)\n",
    "            Al2 = \",\".join(W[tb[it]])\n",
    "            ts[\"Main_character,Written_by\"].append(\"Book about \"+Al1+\" was written by \"+Al2)\n",
    "        if(M[tb[it]][0] != None and P[tb[it]][0] != None):\n",
    "            ts[\"Main_character,Publisher\"] = []\n",
    "            NM = random.sample(list(set(Um)-set(M[tb[it]])),random.randint(1,3))\n",
    "            NP = random.sample(list(set(Up)-set(P[tb[it]])),1)\n",
    "            Al1 = \",\".join(NM)\n",
    "            Al2 = \",\".join(P[tb[it]])\n",
    "            ts[\"Main_character,Publisher\"].append(\"Book about \"+Al1+\" is published by \"+Al2)\n",
    "        if(M[tb[it]][0] != None and S[tb[it]][0] != None):\n",
    "            ts[\"Main_character,Schedule\"] = []\n",
    "            NM = random.sample(list(set(Um)-set(M[tb[it]])),random.randint(1,3))\n",
    "            NS = random.sample(list(set(Us)-set(S[tb[it]])),1)\n",
    "            Al1 = \",\".join(M[tb[it]])\n",
    "            Al2 = \",\".join(NS)\n",
    "            ts[\"Main_character,Schedule\"].append(\"Book about \"+Al1+\" is published \"+Al2)\n",
    "        \n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi_row3(T,N,8,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_row4(tb,dn,F,it,tval=True):\n",
    "    Uw,W = F[\"Written_by\"]\n",
    "    Upd,Pd = F[\"Publication_date\"]\n",
    "    \n",
    "    ts = {}\n",
    "    if(tval):\n",
    "        if(W[tb[it]][0] != None and Pd[tb[it]][0] != None):\n",
    "            ts[\"Written_by,Publication_date\"] = []\n",
    "            Al1 = \",\".join(Pd[tb[it]])\n",
    "            Al2 = \",\".join(W[tb[it]])\n",
    "            ts[\"Written_by,Publication_date\"].append(Al2+\" was alive on \"+Al1)\n",
    "        \n",
    "    else:\n",
    "        if(W[tb[it]][0] != None and Pd[tb[it]][0] != None):\n",
    "            ts[\"Written_by,Publication_date\"] = []\n",
    "            NW = random.sample(list(set(Uw)-set(W[tb[it]])),random.randint(1,2))\n",
    "            NPd = random.sample(list(set(Upd)-set(Pd[tb[it]])),1)\n",
    "            Al1 = \",\".join(NPd)\n",
    "            Al2 = \",\".join(W[tb[it]])\n",
    "            ts[\"Written_by,Publication_date\"].append(Al2+\" was alive on \"+Al1)\n",
    "        \n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi_row4(T,N,-6,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
