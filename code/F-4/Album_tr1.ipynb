{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import sys\n",
    "import json\n",
    "\n",
    "\n",
    "if './' not in sys.path:\n",
    "    sys.path.append('./')\n",
    "    \n",
    "from Album import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:In RainbowsNone\n",
      "\n",
      "Released:10 Oct 2007DATE\n",
      "\n",
      "Recorded:['5 February 2005', '8 June 2007']DATE\n",
      "\n",
      "Genre:['Alternative rock', 'art rock', 'experimental rock', 'art pop']None\n",
      "\n",
      "Length:42:39CARDINAL\n",
      "\n",
      "Label:['Self-released', 'Xurbia Xendless', 'XL', 'TBD']None\n",
      "\n",
      "Producer:['Nigel Godrich']PERSON\n",
      "\n",
      "Tablename:T0_T0ID\n",
      "\n",
      "In Rainbows\n",
      "Producer\n",
      "Label\n",
      "Genre\n",
      "Studio\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-261091931867>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mhypothesis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mpremises_used\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruth_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;31m#             outputFile.write(str(serial_ctr) + \"\\t\" + table_names_list[0] + \"\\t\" + table_names_list[1] + \"\\t\" + json_table + \"\\t\" + statement + \"\\t\" + str(truth_val) + \"\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "table_list = [\"T0\", \"T10\", \"T13\"]\n",
    "tables_list = []\n",
    "global_lists, global_info, fake_adverse_list = {}, {}, {}\n",
    "outputFile = open('results_onefake.txt', \"w+\")\n",
    "\n",
    "fp = open(\"all_jsons.json\",\"r\")\n",
    "all_jsons = json.load(fp)\n",
    "for jsonfile in all_jsons[\"all_json\"]:\n",
    "    jsonfile[\"Title\"] = jsonfile[\"Title\"][0]\n",
    "    jsonfile[\"Released\"] = jsonfile[\"Released\"][0]\n",
    "    jsonfile[\"Recorded\"] = jsonfile[\"Recorded\"][0]\n",
    "    jsonfile[\"Length\"] = jsonfile[\"Length\"][0]\n",
    "    jsonfile[\"Tablename\"] = jsonfile[\"Tablename\"][0]\n",
    "    dictionary = reformDict(jsonfile)\n",
    "    dictionary[\"Tablename\"].val = \"T\"+\"0\"+\"_\"+dictionary[\"Tablename\"].val\n",
    "    tables_list.append(dictionary)\n",
    "    generate_global_lists(dictionary, global_lists, global_info)\n",
    "\n",
    "new_dicts = []\n",
    "# print (len(tables_list))\n",
    "for i in range(0,len(tables_list)):\n",
    "    dictionary = tables_list[i]\n",
    "    preprocesStudio(dictionary, global_lists)\n",
    "    try:\n",
    "        dictionary = constriants(dictionary)\n",
    "    except Exception as e:\n",
    "        # print (dictionary[\"Tablename\"].val)\n",
    "        print(\"error in constraints: \",e)\n",
    "        continue\n",
    "    new_dicts.append(dictionary)\n",
    "    num_of_fake_per_table = 5\n",
    "    for index in range(0,num_of_fake_per_table):\n",
    "        new_dict = table_generator(dictionary, global_lists, global_info, index)\n",
    "        try:\n",
    "            new_dict = constriants(new_dict)\n",
    "        except Exception as e:\n",
    "            # print (new_dict[\"Tablename\"].val)\n",
    "            print(\"error in constraints: \",e)\n",
    "            continue\n",
    "        new_dicts.append(new_dict)\n",
    "\n",
    "for i in range(0,len(new_dicts)):\n",
    "    dictionary = new_dicts[i]\n",
    "    generate_fake_lists(dictionary,fake_adverse_list,global_info)\n",
    "\n",
    "for i in range(0, len(new_dicts)):\n",
    "#     print(\"------------------ \" + str(i) + \"---------------------\")\n",
    "    splitDateRange(new_dicts[i])\n",
    "    preprocessDate(new_dicts[i])  \n",
    "    \n",
    "serial_ctr = 1\n",
    "for i in range(0, len(new_dicts)):    \n",
    "    dictionary = new_dicts[i]\n",
    "    for key, value in dictionary.items():\n",
    "        print( str(key) + \":\" +  str(value.val) + str(value.tag) + \"\\n\" )\n",
    "    \n",
    "    table_name = (dictionary[\"Tablename\"].val).split(\"_\")[-1]\n",
    "\n",
    "    table = []    \n",
    "    premises = []\n",
    "    hypothesis = []\n",
    "    label = []\n",
    "    premises_used = []\n",
    "    json_name = []\n",
    "    #get json\n",
    "    json_table = get_json(dictionary)\n",
    "    json_sent = []\n",
    "    for key in json_table:\n",
    "        json_sent.append(json_table[key][0])\n",
    "    json_sentences = \". \".join(json_sent)\n",
    "    #length rules\n",
    "#     print (\"length_rules\")\n",
    "#     final_result = final_result + lengthRules(dictionary)\n",
    "    #producer\n",
    "    final_result = {}\n",
    "    print (\"Producer\")\n",
    "    final_result[\"Producer\"] = []\n",
    "    final_result[\"Producer\"] = commonRules(dictionary, fake_adverse_list[table_name], 1)\n",
    "#   label\n",
    "    print (\"Label\")\n",
    "    final_result[\"Label\"] = []\n",
    "    final_result[\"Label\"] = commonRules(dictionary, fake_adverse_list[table_name], 2)\n",
    "#   genre\n",
    "    print (\"Genre\")\n",
    "    final_result[\"Genre\"] = []\n",
    "    final_result[\"Genre\"] = commonRules(dictionary, fake_adverse_list[table_name], 3)\n",
    "#   studio\n",
    "    print (\"Studio\")\n",
    "    final_result[\"Studio\"] = []\n",
    "    final_result[\"Studio\"] = commonRules(dictionary, fake_adverse_list[table_name], 4)\n",
    "    \n",
    "#     if final_result:\n",
    "    for key in final_result:\n",
    "        for statement in final_result[key]:\n",
    "            truth_val = statement.split()[-1].strip()\n",
    "            length = len(statement.split())\n",
    "            statement = \" \".join((statement.split()[:length -1])).strip()\n",
    "            if truth_val == \"True\":\n",
    "                truth_val = 1\n",
    "            else:\n",
    "                truth_val = 0\n",
    "            table_name_entry = dictionary[\"Tablename\"].val\n",
    "            table_names_list = table_name_entry.split(\"_\")\n",
    "            table.append(table_names_list[0])\n",
    "            json_name.append(table_names_list[1])\n",
    "            premises.append(json_sentences)\n",
    "            hypothesis.append(statement)\n",
    "            premises_used.append(json_table[key])\n",
    "            label.append(str(truth_val))\n",
    "            \n",
    "#             outputFile.write(str(serial_ctr) + \"\\t\" + table_names_list[0] + \"\\t\" + table_names_list[1] + \"\\t\" + json_table + \"\\t\" + statement + \"\\t\" + str(truth_val) + \"\\n\")\n",
    "#             serial_ctr  += 1\n",
    "            \n",
    "    #date rules\n",
    "#     print (\"dates_rules\")\n",
    "#     final_result = []\n",
    "#     final_result = final_result + dateRules(dictionary)\n",
    "#     if final_result:\n",
    "#         for statement in final_result:\n",
    "#             truth_val = statement.split()[-1].strip()\n",
    "#             length = len(statement.split())\n",
    "#             statement = \" \".join((statement.split()[:length -1])).strip()\n",
    "#             if truth_val == \"True\":\n",
    "#                 truth_val = 1\n",
    "#             else:\n",
    "#                 truth_val = 0\n",
    "#             table_name_entry = dictionary[\"Tablename\"].val\n",
    "#             table_names_list = table_name_entry.split(\"_\")\n",
    "#             outputFile.write(str(serial_ctr) + \"\\t\" + table_names_list[0] + \"\\t\" + table_names_list[1] + \"\\t\" + json_table + \"\\t\" + statement + \"\\t\" + str(truth_val) + \"\\n\")\n",
    "#             serial_ctr  += 1\n",
    "    \n",
    "df = pd.DataFrame({\"table\":table,\"premises\":premises,\"hypothesis\":hypothesis,\"label\":label, \"key & premises_used\":premises_used,\"json_name\":json_name})\n",
    "df.to_csv(\"album_\"+\".csv\",sep=\"\\t\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
